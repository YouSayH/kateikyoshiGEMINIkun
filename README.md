# プロアクティブ・マルチモーダル勉強アシストアプリケーション

## 1. コンセプト

このアプリケーションは、単なるQ&Aツールではありません。**ユーザーの学習環境全体を複合的に捉え、思考の文脈を深く理解し、まるで専属の家庭教師のように能動的（プロアクティブ）に寄り添う**ことを目指して開発された、次世代の学習パートナーです。

カメラ、マイク、そしてユーザーとの対話を通じて多角的な情報を収集し、AIがユーザーの「今」を深く理解することで、最適なサポートを提供します。

---

## 2. 主な機能

### 2.1. 多様なコンテキスト入力

| 機能 | 詳細 |
| :--- | :--- |
| **ファイル分析** | PDFや画像形式の教材ファイルを読み込み、Gemini Visionモデルが内容をOCR処理。学習の主題としてデータベースに保存します。 |
| **音声認識** | マイクからの入力を常時監視。「独り言」は思考ログとして記録し、「OK、アシスタント」等のウェイクワードに続く「命令」は、その瞬間のカメラ映像と共に処理します。 |
| **手の動き追跡** | カスタム学習済みのYOLOv8モデルを使用し、カメラ映像からユーザーの手の動きをリアルタイムで追跡。思考の停止を検知するトリガーとなります。 |
| **定点観測** | 設定された間隔で机の上の状況をGemini Visionモデルが分析。「前回の状況との差分」を検知し、ユーザーの行動変化をログとして記録します。 |

### 2.2. インテリジェントなAIインタラクション

| 機能 | 詳細 |
| :--- | :--- |
| **文脈を理解した応答** | 現在の対話だけでなく、独り言ログ、定点観測ログ、さらには過去の関連セッション情報までを統合した深い文脈に基づき、最適な回答を生成します。 |
| **マルチモーダル応答** | 音声コマンドを検知した際は、その瞬間のカメラ映像とテキスト情報を組み合わせ、ユーザーの意図をより正確に汲み取った応答を生成します。 |
| **自動声かけ** | ユーザーの手が設定時間以上停止していることを検知すると、AIが「どうかしましたか？」のように、プロアクティブに声かけを行います。 |
| **自動キーワード・タイトル生成** | セッション終了後、AIが自動的に会話内容からキーワードを抽出し、内容を要約した最適なタイトルを生成・更新します。 |

### 2.3. 高度なUI/UX

| 機能 | 詳細 |
| :--- | :--- |
| **モダンなチャットUI** | ユーザーとAIの発言がアバター付きの吹き出しで左右に表示され、会話の流れが一目で直感的に分かります。 |
| **リッチテキスト表示** | KaTeXによる数式や、Markdownによる箇条書き・太字などが美しくレンダリングされ、可読性の高い表示を実現します。 |
| **ちらつきのない動的更新** | JavaScript（`QWebChannel`）との連携により、新しいメッセージが追加されても画面がちらつくことなく、スムーズな対話体験を提供します。 |
| **スマートスクロール** | ユーザーがメッセージを送信した時のみ最下部にスクロール。AIからの応答や自動声かけの際は、ユーザーが読んでいる箇所を邪魔しません。 |
| **コード専用コピーボタン** | AIの応答に含まれるコードブロックの右上隅に、そのコードだけをワンクリックでコピーできる専用ボタンが自動で表示されます。 |
| **強化された入力体験** | `Ctrl+Enter`での送信、`↑`/`↓`キーによる送信履歴の呼び出し、入力文字数に応じた入力欄の自動リサイズに対応しています。 |
| **音声入出力制御** | AIが応答を読み上げている間は、その声を拾わないように自動で音声認識を一時停止し、読み上げ完了後に再開します。 |

---

## 3. システムアーキテクチャ

*   **UIフレームワーク**: **PySide6** (Qt for Python)
*   **AIモデル**: **Google Gemini API** (設定画面からタスクごとにモデルを選択可能)
*   **画像認識**: **YOLOv8** (`ultralytics`ライブラリ) - カスタムモデル `best12-2.pt` を使用
*   **データベース**: **SQLite3** - 全てのセッション、対話、ログをローカルに保存
*   **非同期処理**: `QThread`とシグナル/スロット機構を全面的に採用した、UIの応答性を絶対に阻害しない完全非同期・マルチスレッドアーキテクチャ。
    *   `CameraWorker`, `STTWorker`, `TTSWorker`, `VisualObserverWorker`, `DatabaseWorker`等の永続ワーカースレッドが、重い処理をバックグラウンドで実行します。
    *   `GeminiWorker`, `FileProcessingWorker`等の使い捨てスレッドが、API通信などの単発タスクを非同期で実行します。

---

## 4. 環境構築と実行方法

### 4.1. 前提条件
*   Python 3.10以上
*   マイクおよびカメラデバイス

### 4.2. セットアップ手順

1.  **リポジトリのクローンまたはダウンロード**
    ```bash
    git clone [リポジトリURL]
    cd [プロジェクトフォルダ]
    ```

2.  **仮想環境の作成と有効化**
    ```bash
    python -m venv venv
    # Windows
    .\venv\Scripts\activate
    # macOS/Linux
    source venv/bin/activate
    ```

3.  **依存ライブラリのインストール**
    ```bash
    pip install -r requirements.txt
    ```

4.  **必須ファイルの配置**
    *   学習済みYOLOモデル `best12-2.pt` を `models/` フォルダに配置してください。
    *   ローディングGIF `loading.gif` を `assets/` フォルダに配置してください。

5.  **APIキーの設定**
    *   **方法A (推奨)**: プロジェクトのルートディレクトリに `.env` ファイルを作成し、以下のように記述します。
        ```
        GEMINI_API_KEY="ここにあなたのAPIキーを貼り付け"
        ```
    *   **方法B**: アプリケーションを一度起動し、「ファイル」メニューから「設定」を開き、GUI上でAPIキーを入力・保存します。

### 4.3. アプリケーションの実行

```bash
python main.py
```
初回起動時に、`data/` フォルダと `sessions.db` ファイルが自動的に生成されます。

---

## 5. 依存ライブラリ (`requirements.txt`)

```
PySide6
python-dotenv
google-generativeai
ultralytics
opencv-python
Pillow
pyttsx3
SpeechRecognition
PyAudio
PyMuPDF
markdown
pygrabber
```